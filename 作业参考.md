### Thinking1	在实际工作中，FM和MF哪个应用的更多，为什么
** FM在实际工作中应用更多，因为MF具有很大的局限性，它只考虑了user、item两个特征，但在实际工作预测问题中，还包含着很多特征，MF无法利用其他特征。
FM主要用于推荐系统中的预测问题（回归、二分类），作用是引入了更多辅助信息作为特征来进行预测。
##### Thinking2	FFM与FM有哪些区别？

** 他们的主要区别是FM每个特征有唯一一个隐向量，这个隐向量被用来学习与其他任意特征间的影响；而FFM每个特征有多个隐向量，它把相同性质的特征归于同一个field，每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 vi,fj，因此，隐向量不仅与特征相关，也与field相关，假设样本的n个特征属于f个field，那么FFM的二次项有nf个隐向量。

### Thinking3	DeepFM相比于FM解决了哪些问题，原理是怎样的
DeepFM通过多层的神经网络即DNN解决了FM因为计算复杂度的原因一般都只用到二阶特征组合的问题，在低阶和高阶特征组合上更接近真实世界，效果也更好;而且DeepFM end-to-end模型结构避免了特征工程。
DeepFM=FM+DNN，

	FM部分提取低阶特征，Deep部分提取高阶特征，这两部分通过端到端的模型结构共享特征输入（Deep部分则是将fm embedding后的向量作为输入）。
### Thinking4	Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？
**
Baseline算法考虑到了用户打分的偏差bu及商品对整体的偏好bi，基于统计的基准预测线打分，将与个性化无关的部分除去。
	BaselineOnly和KNNBaseline的区别：KNNBaseline是一种基于KNN的协同过滤算法，且考虑了每个用户评分的基线；BaselineOnly是基于统计的基准预测线打分算法，给定用户和Item，得到基于baseline的估计值。
### Thinking5	基于邻域的协同过滤都有哪些算法，请简述原理
** 
UserCF：给用户推荐和他兴趣相似的其他用户喜欢的物品。
ItemCF：给用户推荐和他之前喜欢的物品相似的物品。
两种算法均利用行为的相似度计算用户/物品的相似度，再根据相似度计算用户u对物品i的相似度（UserCF等价于K个邻居对物品i的兴趣度；ItemCF等价于物品i的K个邻居物品，受到用户u的兴趣度），最终为用户u生成推荐列表。